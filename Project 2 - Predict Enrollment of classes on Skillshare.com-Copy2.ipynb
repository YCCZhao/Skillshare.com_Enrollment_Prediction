{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_types = ['fine-art',\n",
    "               'photography',\n",
    "               'graphic-design',\n",
    "               'illustration',\n",
    "               'writing',\n",
    "               'music-production',\n",
    "               'animation',\n",
    "               'ui-ux-design',\n",
    "               'film-production',\n",
    "               'marketing',\n",
    "               'entrepreneurship',\n",
    "               'productivity',\n",
    "               'finance',\n",
    "               'freelance',\n",
    "               'business-analytics',\n",
    "               'management',\n",
    "               'leadership',\n",
    "               'sales',\n",
    "               'human-resources',\n",
    "               'accounting',\n",
    "               'web-development',\n",
    "               'mobile-development',\n",
    "               'it-security',\n",
    "               'data-science',\n",
    "               'game-design',\n",
    "               'product-management',\n",
    "               'crafts',\n",
    "               'culinary',\n",
    "               'health-and-wellness',\n",
    "               'other',\n",
    "               'teaching',\n",
    "               'home-business',\n",
    "               'languages',\n",
    "               'gaming']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_url(class_type_list):\n",
    "    urls_dict = {}\n",
    "    url_template = 'https://www.skillshare.com/browse/%?sort=rating&seeAll=1'\n",
    "    for class_type in class_type_list:\n",
    "        urls_dict[class_type] = url_template.replace('%', class_type)\n",
    "    return urls_dict\n",
    "\n",
    "#urls_dict = make_url(class_types)\n",
    "\n",
    "#with open('class_list_urls.csv', 'w') as f:\n",
    "#    writer = csv.writer(f)\n",
    "#    for key, val in urls_dict.items():\n",
    "#        writer.writerow([key, val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_link(class_types, urls_dict):\n",
    "    for class_type in class_types:\n",
    "        i=0\n",
    "        print('Working on getting list of ' + class_type + ' classes')\n",
    "        url = urls_dict[class_type]\n",
    "        \n",
    "        driver = webdriver.Chrome(chromedriver)\n",
    "        driver.get(url)\n",
    "\n",
    "        try:\n",
    "            close = driver.find_element('xpath', \"//a[contains(@class,'btn-close ss-icon-close')]\")\n",
    "            close.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            i+=1\n",
    "            print(\"Load \", i)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(120)\n",
    "            newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if newHeight == lastHeight:\n",
    "                break\n",
    "            lastHeight = newHeight\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        class_link_tags = soup.find_all('div', attrs={\"class\": \"col-4 class-column rendered \"})\n",
    "        class_links = [class_link_tag.find('p').find('a')['href'] for class_link_tag in class_link_tags]\n",
    "        class_links_dict[class_type] = class_links\n",
    "        driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_links_from_txt(file):\n",
    "    with open(file) as f:\n",
    "        urls_dict = {}\n",
    "        \n",
    "        reader = f.readlines()\n",
    "        \n",
    "        for line in reader:\n",
    "            isStart = True\n",
    "            foo = line.strip().split(',')\n",
    "            for item in foo:\n",
    "                clean_item = item.strip().strip(\"[\").strip(\"]\").strip(\"'\").strip()\n",
    "                if isStart:\n",
    "                    isStart = False\n",
    "                    class_type = clean_item\n",
    "                    urls_dict[class_type] = []\n",
    "                else:\n",
    "                    urls_dict[class_type].append(clean_item)\n",
    "        return urls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_javascript_data(soup):\n",
    "    projects_section = soup.find_all('script', attrs={\"type\": \"text/javascript\"})\n",
    "    \n",
    "    for js in projects_section:\n",
    "        if js.string:\n",
    "            if re.search('.*SS.serverBootstrap =.*',js.text):\n",
    "                javascript = js.string\n",
    "                javascript = javascript.split(\"SS.serverBootstrap = \", 1)\n",
    "\n",
    "                javascript_data = javascript[1].split(\";\\n        \")[0]\n",
    "                javascript_data = json.loads(javascript_data)\n",
    "\n",
    "    return javascript_data\n",
    "\n",
    "#get author link\n",
    "def get_title_and_author(soup):\n",
    "    title = soup.find('title')\n",
    "    \n",
    "    return [item.strip() for item in title.text.split('|')]\n",
    "\n",
    "def get_detial_author_info(javascript_data):\n",
    "    teacherInfo = javascript_data['pageData']['sectionData']['teacherInfo']\n",
    "    \n",
    "    return teacherInfo['fullName'], teacherInfo['headline'], teacherInfo['profileUrl']\n",
    "    \n",
    "#find media \n",
    "def get_class_description(soup):\n",
    "    description_tag = soup.find('div', attrs={\"class\": \"about-this-class\"}).find('div', attrs={\"class\": \"rich-content-wrapper\"})\n",
    "    \n",
    "    class_description = \"\"\n",
    "    \n",
    "    images, hyperlinks = 0, 0\n",
    "    for paragraph in description_tag.findChildren():\n",
    "        class_description += paragraph.text\n",
    "        if paragraph.name == 'img':\n",
    "            images += 1\n",
    "        elif paragraph.name == 'a':\n",
    "            hyperlinks += 1\n",
    "            \n",
    "    return len(class_description), images, hyperlinks\n",
    "\n",
    "#extract info\n",
    "def get_video_length(soup):\n",
    "    video_content_tag = soup.find('div', attrs={\"class\": \"summary\"}).text.strip().strip('\\n').strip()\n",
    "    \n",
    "    pattern_number = '(\\d+)*'\n",
    "    pattern_length = '(\\d+)(?=m)'\n",
    "    video_num = re.search(pattern_number, video_content_tag).group(0)\n",
    "    video_length = re.search(pattern_length, video_content_tag).group(0)\n",
    "    \n",
    "    return video_num, video_length\n",
    "\n",
    "\n",
    "# get link\n",
    "def get_tags(soup):\n",
    "    tags = []\n",
    "    tags_section = soup.find('div', attrs={\"class\": \"tags-section\"})\n",
    "    for tag in tags_section.find_all('a'):\n",
    "        tags.append(tag.text.strip())\n",
    "        \n",
    "    return tags\n",
    "        \n",
    "def get_project_authors(javascript_data):    \n",
    "    try:\n",
    "        return [project['author']['fullName'] for project in javascript_data['pageData']['sectionData']['topProjects']]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_class_sku(javascript_data):\n",
    "    return javascript_data['classData']['sku']\n",
    "\n",
    "def isPremium(javascript_data):\n",
    "    return javascript_data['pageData']['headerData']['tagText'] == 'Premium class'\n",
    "\n",
    "def get_start_date(javascript_data):\n",
    "    return javascript_data['pageData']['syllabusData']['startTs']\n",
    "\n",
    "def get_enrollment_number(javascript_data):\n",
    "    return javascript_data['pageData']['sectionData']['numStudents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = 'class_urls-1.csv'\n",
    "urls_dict = get_links_from_txt(file)\n",
    "#urls_dict.keys()\n",
    "#class_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': [],\n",
       " 'class_sku': [],\n",
       " 'description_image_number': [],\n",
       " 'description_length': [],\n",
       " 'description_link_number': [],\n",
       " 'enrollment_number': [],\n",
       " 'paid_class': [],\n",
       " 'sample_project': [],\n",
       " 'start_date': [],\n",
       " 'tags': [],\n",
       " 'teacher': [],\n",
       " 'teacher_profile': [],\n",
       " 'teacher_title': [],\n",
       " 'video_length_min': [],\n",
       " 'video_number': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['class_name',\n",
    "          'teacher',\n",
    "          'teacher_title',\n",
    "          'teacher_profile',\n",
    "          'description_length',\n",
    "          'description_image_number',\n",
    "          'description_link_number',\n",
    "          'video_number',\n",
    "          'video_length_min',\n",
    "          'tags',\n",
    "          'sample_project',\n",
    "          'class_sku',\n",
    "          'paid_class',\n",
    "          'start_date',\n",
    "          'enrollment_number']\n",
    "class_data = {col: [] for col in columns}\n",
    "class_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on  health-and-wellness\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "stop here\n"
     ]
    }
   ],
   "source": [
    "#def parse(class_type):\n",
    "access_denied = False\n",
    "for class_type in class_types[28:35]:\n",
    "    if access_denied:\n",
    "        break\n",
    "            \n",
    "    print(\"working on \", class_type)\n",
    "    class_data = {col: [] for col in columns}\n",
    "    \n",
    "    i=0\n",
    "    partition = 0\n",
    "    \n",
    "    for this_class in urls_dict[class_type]: \n",
    "        #print(this_class)\n",
    "        time.sleep(.5+2*random.random())\n",
    "        ua = UserAgent()\n",
    "        user_agent = {'User-agent': ua.random}\n",
    "        response  = requests.get(this_class, headers = user_agent)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "        \n",
    "        \n",
    "        if response.status_code != 200 and re.search('Access denied.*', soup.find('title').text):\n",
    "            partition += 1\n",
    "            pickle_title = class_type + str(partition) + \".pickle\"\n",
    "            pickle_out = open(pickle_title,\"wb\")\n",
    "            pickle.dump(class_data, pickle_out)\n",
    "            pickle_out.close()\n",
    "            print(\"stop here\")\n",
    "            access_denied = True\n",
    "            #class_data = {col: [] for col in columns}\n",
    "            #time.sleep(60*60)\n",
    "            break\n",
    "            \n",
    "        #elif response.status_code != 200:\n",
    "        #    time.sleep(60)\n",
    "        #    continue\n",
    "        \n",
    "        else:\n",
    "            i+=1\n",
    "            if i%10==0:\n",
    "                print(i)\n",
    "\n",
    "            try:\n",
    "                javascript_data = get_javascript_data(soup)\n",
    "\n",
    "                class_data['class_name'].append(get_title_and_author(soup)[0])\n",
    "\n",
    "                teacher, teacher_title, teacher_profile = get_detial_author_info(javascript_data)\n",
    "                class_data['teacher'].append(teacher)\n",
    "                class_data['teacher_title'].append(teacher_title)\n",
    "                class_data['teacher_profile'].append(teacher_profile)\n",
    "\n",
    "                description_length, description_image_number, description_link_number = get_class_description(soup)\n",
    "\n",
    "                class_data['description_length'].append(description_length)\n",
    "                class_data['description_image_number'].append(description_image_number)\n",
    "                class_data['description_link_number'].append(description_link_number)\n",
    "\n",
    "                video_number, video_length_min = get_video_length(soup)\n",
    "                class_data['video_number'].append(video_number)\n",
    "                class_data['video_length_min'].append(video_length_min)\n",
    "\n",
    "                class_data['tags'].append(get_tags(soup))\n",
    "                class_data['sample_project'].append(teacher in get_project_authors(javascript_data))\n",
    "                class_data['class_sku'].append(get_class_sku(javascript_data))\n",
    "                class_data['paid_class'].append(isPremium(javascript_data))\n",
    "                class_data['start_date'].append(get_start_date(javascript_data))\n",
    "                class_data['enrollment_number'].append(get_enrollment_number(javascript_data))\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    pickle_title = class_type + \".pickle\"\n",
    "    pickle_out = open(pickle_title,\"wb\")\n",
    "    pickle.dump(class_data, pickle_out)\n",
    "    pickle_out.close()\n",
    "    #return 0\n",
    "\n",
    "#type(p)\n",
    "#with Pool(3) as p:\n",
    "#    p.map(parse, class_types[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_title = class_type + \".pickle\"\n",
    "pickle_out = open(pickle_title,\"wb\")\n",
    "pickle.dump(class_data, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for test_case in test_cases:\n",
    "    response = requests.get(test_case)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "    javascript_data = get_javascript_data(soup)\n",
    "    \n",
    "    print(get_title_and_author(soup))\n",
    "    print(get_detial_author_info(javascript_data))\n",
    "    print(get_class_description(soup))    \n",
    "    print(get_video_length(soup))\n",
    "    print(get_tags(soup))\n",
    "    print(get_project_authors(javascript_data))\n",
    "    print(get_class_sku(javascript_data))\n",
    "    print(isPremium(javascript_data))\n",
    "    print(javascript_data['pageData']['headerData']['tagText'] == 'Premium class')\n",
    "    print(get_start_date(javascript_data))\n",
    "    print(get_enrollment_number(javascript_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_class_link(class_types, urls_dict)\n",
    "\n",
    "with open('class_urls.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for key, val in class_links_dict.items():\n",
    "        writer.writerow([key, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "class_links_dict = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
