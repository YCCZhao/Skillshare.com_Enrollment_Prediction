{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_types = ['fine-art',\n",
    "               'photography',\n",
    "               'graphic-design',\n",
    "               'illustration',\n",
    "               'writing',\n",
    "               'music-production',\n",
    "               'animation',\n",
    "               'ui-ux-design',\n",
    "               'film-production',\n",
    "               'marketing',\n",
    "               'entrepreneurship',\n",
    "               'productivity',\n",
    "               'finance',\n",
    "               'freelance',\n",
    "               'business-analytics',\n",
    "               'management',\n",
    "               'leadership',\n",
    "               'sales',\n",
    "               'human-resources',\n",
    "               'accounting',\n",
    "               'web-development',\n",
    "               'mobile-development',\n",
    "               'it-security',\n",
    "               'data-science',\n",
    "               'game-design',\n",
    "               'product-management',\n",
    "               'crafts',\n",
    "               'culinary',\n",
    "               'health-and-wellness',\n",
    "               'other',\n",
    "               'teaching',\n",
    "               'home-business',\n",
    "               'languages',\n",
    "               'gaming']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_url(class_type_list):\n",
    "    urls_dict = {}\n",
    "    url_template = 'https://www.skillshare.com/browse/%?sort=rating&seeAll=1'\n",
    "    for class_type in class_type_list:\n",
    "        urls_dict[class_type] = url_template.replace('%', class_type)\n",
    "    return urls_dict\n",
    "\n",
    "#urls_dict = make_url(class_types)\n",
    "\n",
    "#with open('class_list_urls.csv', 'w') as f:\n",
    "#    writer = csv.writer(f)\n",
    "#    for key, val in urls_dict.items():\n",
    "#        writer.writerow([key, val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_link(class_types, urls_dict):\n",
    "    for class_type in class_types:\n",
    "        i=0\n",
    "        print('Working on getting list of ' + class_type + ' classes')\n",
    "        url = urls_dict[class_type]\n",
    "        \n",
    "        driver = webdriver.Chrome(chromedriver)\n",
    "        driver.get(url)\n",
    "\n",
    "        try:\n",
    "            close = driver.find_element('xpath', \"//a[contains(@class,'btn-close ss-icon-close')]\")\n",
    "            close.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            i+=1\n",
    "            print(\"Load \", i)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(120)\n",
    "            newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if newHeight == lastHeight:\n",
    "                break\n",
    "            lastHeight = newHeight\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        class_link_tags = soup.find_all('div', attrs={\"class\": \"col-4 class-column rendered \"})\n",
    "        class_links = [class_link_tag.find('p').find('a')['href'] for class_link_tag in class_link_tags]\n",
    "        class_links_dict[class_type] = class_links\n",
    "        driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_links_from_txt(file):\n",
    "    with open(file) as f:\n",
    "        urls_dict = {}\n",
    "        \n",
    "        reader = f.readlines()\n",
    "        \n",
    "        for line in reader:\n",
    "            isStart = True\n",
    "            foo = line.strip().split(',')\n",
    "            for item in foo:\n",
    "                clean_item = item.strip().strip(\"[\").strip(\"]\").strip(\"'\").strip()\n",
    "                if isStart:\n",
    "                    isStart = False\n",
    "                    class_type = clean_item\n",
    "                    urls_dict[class_type] = []\n",
    "                else:\n",
    "                    urls_dict[class_type].append(clean_item)\n",
    "        return urls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_javascript_data(soup):\n",
    "    projects_section = soup.find_all('script', attrs={\"type\": \"text/javascript\"})\n",
    "    \n",
    "    for js in projects_section:\n",
    "        if js.string:\n",
    "            if re.search('.*SS.serverBootstrap =.*',js.text):\n",
    "                javascript = js.string\n",
    "                javascript = javascript.split(\"SS.serverBootstrap = \", 1)\n",
    "\n",
    "                javascript_data = javascript[1].split(\";\\n        \")[0]\n",
    "                javascript_data = json.loads(javascript_data)\n",
    "\n",
    "    return javascript_data\n",
    "\n",
    "#get author link\n",
    "def get_title_and_author(soup):\n",
    "    title = soup.find('title')\n",
    "    \n",
    "    return [item.strip() for item in title.text.split('|')]\n",
    "\n",
    "def get_detial_author_info(javascript_data):\n",
    "    teacherInfo = javascript_data['pageData']['sectionData']['teacherInfo']\n",
    "    \n",
    "    return teacherInfo['fullName'], teacherInfo['headline'], teacherInfo['profileUrl']\n",
    "    \n",
    "#find media \n",
    "def get_class_description(soup):\n",
    "    description_tag = soup.find('div', attrs={\"class\": \"about-this-class\"}).find('div', attrs={\"class\": \"rich-content-wrapper\"})\n",
    "    \n",
    "    class_description = \"\"\n",
    "    \n",
    "    images, hyperlinks = 0, 0\n",
    "    for paragraph in description_tag.findChildren():\n",
    "        class_description += paragraph.text\n",
    "        if paragraph.name == 'img':\n",
    "            images += 1\n",
    "        elif paragraph.name == 'a':\n",
    "            hyperlinks += 1\n",
    "            \n",
    "    return len(class_description), images, hyperlinks\n",
    "\n",
    "#extract info\n",
    "def get_video_length(soup):\n",
    "    video_content_tag = soup.find('div', attrs={\"class\": \"summary\"}).text.strip().strip('\\n').strip()\n",
    "    \n",
    "    pattern_number = '(\\d+)*'\n",
    "    pattern_length = '(\\d+)(?=m)'\n",
    "    video_num = re.search(pattern_number, video_content_tag).group(0)\n",
    "    video_length = re.search(pattern_length, video_content_tag).group(0)\n",
    "    \n",
    "    return video_num, video_length\n",
    "\n",
    "\n",
    "# get link\n",
    "def get_tags(soup):\n",
    "    tags = []\n",
    "    tags_section = soup.find('div', attrs={\"class\": \"tags-section\"})\n",
    "    for tag in tags_section.find_all('a'):\n",
    "        tags.append(tag.text.strip())\n",
    "        \n",
    "    return tags\n",
    "        \n",
    "def get_project_authors(javascript_data):    \n",
    "    try:\n",
    "        return [project['author']['fullName'] for project in javascript_data['pageData']['sectionData']['topProjects']]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_class_sku(javascript_data):\n",
    "    return javascript_data['classData']['sku']\n",
    "\n",
    "def isPremium(javascript_data):\n",
    "    return javascript_data['pageData']['headerData']['tagText'] == 'Premium class'\n",
    "\n",
    "def get_start_date(javascript_data):\n",
    "    return javascript_data['pageData']['syllabusData']['startTs']\n",
    "\n",
    "def get_enrollment_number(javascript_data):\n",
    "    return javascript_data['pageData']['sectionData']['numStudents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = 'class_urls-1.csv'\n",
    "urls_dict = get_links_from_txt(file)\n",
    "#urls_dict.keys()\n",
    "#class_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': [],\n",
       " 'class_sku': [],\n",
       " 'description_image_number': [],\n",
       " 'description_length': [],\n",
       " 'description_link_number': [],\n",
       " 'enrollment_number': [],\n",
       " 'paid_class': [],\n",
       " 'sample_project': [],\n",
       " 'start_date': [],\n",
       " 'tags': [],\n",
       " 'teacher': [],\n",
       " 'teacher_profile': [],\n",
       " 'teacher_title': [],\n",
       " 'video_length_min': [],\n",
       " 'video_number': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['class_name',\n",
    "          'teacher',\n",
    "          'teacher_title',\n",
    "          'teacher_profile',\n",
    "          'description_length',\n",
    "          'description_image_number',\n",
    "          'description_link_number',\n",
    "          'video_number',\n",
    "          'video_length_min',\n",
    "          'tags',\n",
    "          'sample_project',\n",
    "          'class_sku',\n",
    "          'paid_class',\n",
    "          'start_date',\n",
    "          'enrollment_number']\n",
    "class_data = {col: [] for col in columns}\n",
    "class_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on  web-development\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b1e57fad0e9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mua\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUserAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0muser_agent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'User-agent'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mua\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mresponse\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    516\u001b[0m         }\n\u001b[0;32m    517\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m                 )\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 141\u001b[1;33m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mfamily\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallowed_gai_family\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0msock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    741\u001b[0m     \u001b[1;31m# and socket type values to enum constants.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m         addrlist.append((_intenum_converter(af, AddressFamily),\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#def parse(class_type):\n",
    "access_denied = False\n",
    "for class_type in class_types[20:25]:\n",
    "    if access_denied:\n",
    "        break\n",
    "            \n",
    "    print(\"working on \", class_type)\n",
    "    class_data = {col: [] for col in columns}\n",
    "    \n",
    "    i=0\n",
    "    partition = 0\n",
    "    \n",
    "    for this_class in urls_dict[class_type]: \n",
    "        #print(this_class)\n",
    "        time.sleep(.5+2*random.random())\n",
    "        ua = UserAgent()\n",
    "        user_agent = {'User-agent': ua.random}\n",
    "        response  = requests.get(this_class, headers = user_agent)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "        \n",
    "        \n",
    "        if response.status_code != 200 and re.search('Access denied.*', soup.find('title').text):\n",
    "            partition += 1\n",
    "            pickle_title = class_type + str(partition) + \".pickle\"\n",
    "            pickle_out = open(pickle_title,\"wb\")\n",
    "            pickle.dump(class_data, pickle_out)\n",
    "            pickle_out.close()\n",
    "            print(\"stop here\")\n",
    "            access_denied = True\n",
    "            #class_data = {col: [] for col in columns}\n",
    "            #time.sleep(60*60)\n",
    "            break\n",
    "            \n",
    "        #elif response.status_code != 200:\n",
    "        #    time.sleep(60)\n",
    "        #    continue\n",
    "        \n",
    "        else:\n",
    "            i+=1\n",
    "            if i%10==0:\n",
    "                print(i)\n",
    "\n",
    "            try:\n",
    "                javascript_data = get_javascript_data(soup)\n",
    "\n",
    "                class_data['class_name'].append(get_title_and_author(soup)[0])\n",
    "\n",
    "                teacher, teacher_title, teacher_profile = get_detial_author_info(javascript_data)\n",
    "                class_data['teacher'].append(teacher)\n",
    "                class_data['teacher_title'].append(teacher_title)\n",
    "                class_data['teacher_profile'].append(teacher_profile)\n",
    "\n",
    "                description_length, description_image_number, description_link_number = get_class_description(soup)\n",
    "\n",
    "                class_data['description_length'].append(description_length)\n",
    "                class_data['description_image_number'].append(description_image_number)\n",
    "                class_data['description_link_number'].append(description_link_number)\n",
    "\n",
    "                video_number, video_length_min = get_video_length(soup)\n",
    "                class_data['video_number'].append(video_number)\n",
    "                class_data['video_length_min'].append(video_length_min)\n",
    "\n",
    "                class_data['tags'].append(get_tags(soup))\n",
    "                class_data['sample_project'].append(teacher in get_project_authors(javascript_data))\n",
    "                class_data['class_sku'].append(get_class_sku(javascript_data))\n",
    "                class_data['paid_class'].append(isPremium(javascript_data))\n",
    "                class_data['start_date'].append(get_start_date(javascript_data))\n",
    "                class_data['enrollment_number'].append(get_enrollment_number(javascript_data))\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    pickle_title = class_type + \".pickle\"\n",
    "    pickle_out = open(pickle_title,\"wb\")\n",
    "    pickle.dump(class_data, pickle_out)\n",
    "    pickle_out.close()\n",
    "    #return 0\n",
    "\n",
    "#type(p)\n",
    "#with Pool(3) as p:\n",
    "#    p.map(parse, class_types[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_proxy  = \"http://10.10.1.10:3128\"\n",
    "https_proxy = \"https://10.10.1.11:1080\"\n",
    "ftp_proxy   = \"ftp://10.10.1.10:3128\"\n",
    "\n",
    "proxyDict = { \n",
    "              \"http\"  : http_proxy, \n",
    "              \"https\" : https_proxy, \n",
    "              \"ftp\"   : ftp_proxy\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_title = class_type + \".pickle\"\n",
    "pickle_out = open(pickle_title,\"wb\")\n",
    "pickle.dump(class_data, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for test_case in test_cases:\n",
    "    response = requests.get(test_case)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "    javascript_data = get_javascript_data(soup)\n",
    "    \n",
    "    print(get_title_and_author(soup))\n",
    "    print(get_detial_author_info(javascript_data))\n",
    "    print(get_class_description(soup))    \n",
    "    print(get_video_length(soup))\n",
    "    print(get_tags(soup))\n",
    "    print(get_project_authors(javascript_data))\n",
    "    print(get_class_sku(javascript_data))\n",
    "    print(isPremium(javascript_data))\n",
    "    print(javascript_data['pageData']['headerData']['tagText'] == 'Premium class')\n",
    "    print(get_start_date(javascript_data))\n",
    "    print(get_enrollment_number(javascript_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_class_link(class_types, urls_dict)\n",
    "\n",
    "with open('class_urls.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for key, val in class_links_dict.items():\n",
    "        writer.writerow([key, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "class_links_dict = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
